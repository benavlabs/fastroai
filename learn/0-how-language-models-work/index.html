
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
        <meta name="description" content="Lightweight AI orchestration built on PydanticAI. Cost tracking, pipelines, and production-safe tools.">
      
      
        <meta name="author" content="Benav Labs LLC">
      
      
        <link rel="canonical" href="https://benavlabs.github.io/fastroai/learn/0-how-language-models-work/">
      
      
        <link rel="prev" href="../">
      
      
        <link rel="next" href="../1-what-llms-can-and-cant-do/">
      
      
      <link rel="icon" href="../../assets/logo-icon.png">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.6.22">
    
    
      
        <title>0. How Language Models Work - FastroAI</title>
      
    
    
      <link rel="stylesheet" href="../../assets/stylesheets/main.84d31ad4.min.css">
      
        
        <link rel="stylesheet" href="../../assets/stylesheets/palette.06af60db.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Ubuntu:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Ubuntu";--md-code-font:"Roboto Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../../assets/_mkdocstrings.css">
    
      <link rel="stylesheet" href="../../assets/extra.css">
    
    <script>__md_scope=new URL("../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="pink" data-md-color-accent="pink">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#how-language-models-work" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

<header class="md-header" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../.." title="FastroAI" class="md-header__button md-logo" aria-label="FastroAI" data-md-component="logo">
      
  <img src="../../assets/logo-icon.png" alt="logo">

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            FastroAI
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              0. How Language Models Work
            
          </span>
        </div>
      </div>
    </div>
    
      
        <form class="md-header__option" data-md-component="palette">
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme: light)" data-md-color-scheme="default" data-md-color-primary="pink" data-md-color-accent="pink"  aria-label="Switch to dark mode"  type="radio" name="__palette" id="__palette_0">
    
      <label class="md-header__button md-icon" title="Switch to dark mode" for="__palette_1" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a4 4 0 0 0-4 4 4 4 0 0 0 4 4 4 4 0 0 0 4-4 4 4 0 0 0-4-4m0 10a6 6 0 0 1-6-6 6 6 0 0 1 6-6 6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12z"/></svg>
      </label>
    
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme: dark)" data-md-color-scheme="slate" data-md-color-primary="pink" data-md-color-accent="pink"  aria-label="Switch to light mode"  type="radio" name="__palette" id="__palette_1">
    
      <label class="md-header__button md-icon" title="Switch to light mode" for="__palette_0" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 18c-.89 0-1.74-.2-2.5-.55C11.56 16.5 13 14.42 13 12s-1.44-4.5-3.5-5.45C10.26 6.2 11.11 6 12 6a6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12z"/></svg>
      </label>
    
  
</form>
      
    
    
      <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      
      
        <label class="md-header__button md-icon" for="__search">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        </label>
        <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
        <div class="md-search__suggest" data-md-component="search-suggest"></div>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
      
    
    
      <div class="md-header__source">
        <a href="https://github.com/benavlabs/fastroai" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M439.6 236.1 244 40.5c-5.4-5.5-12.8-8.5-20.4-8.5s-15 3-20.4 8.4L162.5 81l51.5 51.5c27.1-9.1 52.7 16.8 43.4 43.7l49.7 49.7c34.2-11.8 61.2 31 35.5 56.7-26.5 26.5-70.2-2.9-56-37.3L240.3 199v121.9c25.3 12.5 22.3 41.8 9.1 55-6.4 6.4-15.2 10.1-24.3 10.1s-17.8-3.6-24.3-10.1c-17.6-17.6-11.1-46.9 11.2-56v-123c-20.8-8.5-24.6-30.7-18.6-45L142.6 101 8.5 235.1C3 240.6 0 247.9 0 255.5s3 15 8.5 20.4l195.6 195.7c5.4 5.4 12.7 8.4 20.4 8.4s15-3 20.4-8.4l194.7-194.7c5.4-5.4 8.4-12.8 8.4-20.4s-3-15-8.4-20.4"/></svg>
  </div>
  <div class="md-source__repository">
    benavlabs/fastroai
  </div>
</a>
      </div>
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
            
<nav class="md-tabs" aria-label="Tabs" data-md-component="tabs">
  <div class="md-grid">
    <ul class="md-tabs__list">
      
        
  
  
  
  
    <li class="md-tabs__item">
      <a href="../.." class="md-tabs__link">
        
  
  
    
  
  FastroAI

      </a>
    </li>
  

      
        
  
  
  
    
  
  
    
    
      <li class="md-tabs__item md-tabs__item--active">
        <a href="../" class="md-tabs__link">
          
  
  
    
  
  Learn

        </a>
      </li>
    
  

      
        
  
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../guides/" class="md-tabs__link">
          
  
  
    
  
  Guides

        </a>
      </li>
    
  

      
        
  
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../recipes/" class="md-tabs__link">
          
  
  
    
  
  Recipes

        </a>
      </li>
    
  

      
        
  
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../api/" class="md-tabs__link">
          
  
  
    
  
  API Reference

        </a>
      </li>
    
  

      
        
  
  
  
  
    <li class="md-tabs__item">
      <a href="../../changelog/" class="md-tabs__link">
        
  
  
    
  
  Changelog

      </a>
    </li>
  

      
    </ul>
  </div>
</nav>
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


  


<nav class="md-nav md-nav--primary md-nav--lifted" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../.." title="FastroAI" class="md-nav__button md-logo" aria-label="FastroAI" data-md-component="logo">
      
  <img src="../../assets/logo-icon.png" alt="logo">

    </a>
    FastroAI
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/benavlabs/fastroai" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M439.6 236.1 244 40.5c-5.4-5.5-12.8-8.5-20.4-8.5s-15 3-20.4 8.4L162.5 81l51.5 51.5c27.1-9.1 52.7 16.8 43.4 43.7l49.7 49.7c34.2-11.8 61.2 31 35.5 56.7-26.5 26.5-70.2-2.9-56-37.3L240.3 199v121.9c25.3 12.5 22.3 41.8 9.1 55-6.4 6.4-15.2 10.1-24.3 10.1s-17.8-3.6-24.3-10.1c-17.6-17.6-11.1-46.9 11.2-56v-123c-20.8-8.5-24.6-30.7-18.6-45L142.6 101 8.5 235.1C3 240.6 0 247.9 0 255.5s3 15 8.5 20.4l195.6 195.7c5.4 5.4 12.7 8.4 20.4 8.4s15-3 20.4-8.4l194.7-194.7c5.4-5.4 8.4-12.8 8.4-20.4s-3-15-8.4-20.4"/></svg>
  </div>
  <div class="md-source__repository">
    benavlabs/fastroai
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../.." class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    FastroAI
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
    
  
  
  
    
    
      
        
          
        
      
        
      
        
      
        
      
        
      
        
      
    
    
    
      
        
        
      
      
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2" checked>
        
          
          <div class="md-nav__link md-nav__container">
            <a href="../" class="md-nav__link ">
              
  
  
  <span class="md-ellipsis">
    Learn
    
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_2" id="__nav_2_label" tabindex="">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_2_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_2">
            <span class="md-nav__icon md-icon"></span>
            Learn
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  
  <span class="md-ellipsis">
    0. How Language Models Work
    
  </span>
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  
  <span class="md-ellipsis">
    0. How Language Models Work
    
  </span>
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#the-challenge-computers-and-text" class="md-nav__link">
    <span class="md-ellipsis">
      The Challenge: Computers and Text
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#representing-text-as-numbers" class="md-nav__link">
    <span class="md-ellipsis">
      Representing Text as Numbers
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#tokenization" class="md-nav__link">
    <span class="md-ellipsis">
      Tokenization
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#how-language-models-work_1" class="md-nav__link">
    <span class="md-ellipsis">
      How Language Models Work
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#the-full-pipeline" class="md-nav__link">
    <span class="md-ellipsis">
      The Full Pipeline
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#practical-implications" class="md-nav__link">
    <span class="md-ellipsis">
      Practical Implications
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../1-what-llms-can-and-cant-do/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    1. What LLMs Can and Can't Do
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../2-your-first-agent/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    2. Your First Agent
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../3-letting-agents-do-things/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    3. Letting Agents Do Things
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../4-getting-data-back/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    4. Getting Data Back, Not Just Text
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
          
        
      
        
      
        
      
        
      
        
      
        
      
    
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3" >
        
          
          <div class="md-nav__link md-nav__container">
            <a href="../../guides/" class="md-nav__link ">
              
  
  
  <span class="md-ellipsis">
    Guides
    
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_3" id="__nav_3_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3">
            <span class="md-nav__icon md-icon"></span>
            Guides
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../guides/fastro-agent/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    FastroAgent
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../guides/cost-calculator/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Cost Calculator
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../guides/pipelines/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Pipelines
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../guides/safe-tools/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Safe Tools
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../guides/tracing/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Tracing
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
          
        
      
    
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4" >
        
          
          <div class="md-nav__link md-nav__container">
            <a href="../../recipes/" class="md-nav__link ">
              
  
  
  <span class="md-ellipsis">
    Recipes
    
  </span>
  

            </a>
            
          </div>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_4">
            <span class="md-nav__icon md-icon"></span>
            Recipes
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
          
        
      
        
      
        
      
        
      
        
      
        
      
    
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5" >
        
          
          <div class="md-nav__link md-nav__container">
            <a href="../../api/" class="md-nav__link ">
              
  
  
  <span class="md-ellipsis">
    API Reference
    
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_5" id="__nav_5_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_5_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5">
            <span class="md-nav__icon md-icon"></span>
            API Reference
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../api/agent/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Agent
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../api/pipelines/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Pipelines
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../api/tools/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Tools
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../api/usage/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Usage
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../api/tracing/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Tracing
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../changelog/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Changelog
    
  </span>
  

      </a>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#the-challenge-computers-and-text" class="md-nav__link">
    <span class="md-ellipsis">
      The Challenge: Computers and Text
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#representing-text-as-numbers" class="md-nav__link">
    <span class="md-ellipsis">
      Representing Text as Numbers
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#tokenization" class="md-nav__link">
    <span class="md-ellipsis">
      Tokenization
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#how-language-models-work_1" class="md-nav__link">
    <span class="md-ellipsis">
      How Language Models Work
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#the-full-pipeline" class="md-nav__link">
    <span class="md-ellipsis">
      The Full Pipeline
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#practical-implications" class="md-nav__link">
    <span class="md-ellipsis">
      Practical Implications
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  


  
  


<h1 id="how-language-models-work">How Language Models Work<a class="headerlink" href="#how-language-models-work" title="Permanent link">&para;</a></h1>
<p><strong>Understanding what happens between your code and the AI response.</strong></p>
<p>When you call an LLM API, something happens between your text and the response. Hopefully understanding what's actually happening will help you build better applications and debug problems when things go wrong. Either way it's a really cool thing to learn.</p>
<p>You don't need to understand all of the math, but you do need to understand the mechanics well enough to know why prompts work the way they do, why costs scale with tokens, and why models sometimes produce nonsense.</p>
<h2 id="the-challenge-computers-and-text">The Challenge: Computers and Text<a class="headerlink" href="#the-challenge-computers-and-text" title="Permanent link">&para;</a></h2>
<p>Computers have been working with text since the beginning. Early systems stored characters as numbers (ASCII gave us 'A' = 65, 'B' = 66, and so on), and we could search for exact strings, count word frequencies, and match patterns with regular expressions.</p>
<p>This worked fine for many tasks. Database queries, log parsing, form validation - if you know exactly what you're looking for, exact string matching is fast and reliable.</p>
<p>But language is messy. Someone reports their app is "broken" when your error logs say "connection timeout." A user asks about "cheap options" when your pricing page says "affordable plans." Exact string matching doesn't understand that these refer to the same things.</p>
<p>The field of Natural Language Processing (NLP) spent decades trying to solve this. Early approaches used rules and dictionaries - manually curated synonym lists, grammar parsers, sentiment lexicons. These worked for narrow domains but getting nuance right is hard. You can't anticipate every way someone might phrase a question.</p>
<p>What we actually need is a system that understands meaning, not just matches characters. But there's a fundamental constraint: computers work with numbers. They can add, compare, and transform numbers easily. They're terrible at understanding that "I'm furious" and "I'm angry" mean roughly the same thing, or that "bank" means something different in "river bank" versus "bank account."</p>
<p>If we want computers to work with language meaningfully, we need to turn text into numbers somehow. But how?</p>
<h2 id="representing-text-as-numbers">Representing Text as Numbers<a class="headerlink" href="#representing-text-as-numbers" title="Permanent link">&para;</a></h2>
<p>If we want to find text that's semantically similar (not just string-matching), we need some way to measure how "close" two pieces of text are. We need a distance metric.</p>
<p>Let's start simple. The words "king" and "queen" are related - both are royalty. Maybe we can use letter patterns? Compare characters, count letters, look at structure.</p>
<p>But then "king" and "ring" share three out of four letters. Structurally they're almost identical. Yet semantically, "king" and "queen" are far more related than "king" and "ring."</p>
<p>Letter structure doesn't capture meaning. The only thing computers can measure distance between is numbers. So we have two problems:</p>
<ol>
<li>How do we turn words into numbers?</li>
<li>How do we make the distance between those numbers represent semantic similarity?</li>
</ol>
<hr />
<p>The most obvious approach to turn words into numbers is giving each word a unique identifier. "Apples" is word #1, "oranges" is word #2, "trucks" is word #3. We can represent this as a vector where only one position is "hot" (set to 1):</p>
<table>
<thead>
<tr>
<th></th>
<th>I</th>
<th>like</th>
<th>apples</th>
<th>oranges</th>
<th>trucks</th>
</tr>
</thead>
<tbody>
<tr>
<td>I like apples</td>
<td>1</td>
<td>1</td>
<td>1</td>
<td>0</td>
<td>0</td>
</tr>
<tr>
<td>I like oranges</td>
<td>1</td>
<td>1</td>
<td>0</td>
<td>1</td>
<td>0</td>
</tr>
<tr>
<td>I like trucks</td>
<td>1</td>
<td>1</td>
<td>0</td>
<td>0</td>
<td>1</td>
</tr>
</tbody>
</table>
<p>Now we have text as numbers. But if you have 50,000 words in your vocabulary, each word becomes a vector of 50,000 numbers with a single 1 and 49,999 zeros. These vectors are huge and mostly empty - we call them "sparse."</p>
<p>Also, the representation tells us nothing about meaning (the second problem we need to tackle). The distance between "apples" and "oranges" might be exactly the same as the distance between "apples" and "trucks." We've turned text into numbers, but those numbers don't capture any semantic information.</p>
<hr />
<p>Think about your phone's autocomplete. When you type "I had a delicious," it suggests "meal," "dinner," or "breakfast" - not "quantum" or "democracy." It learned that certain words follow "delicious" more often than others by analyzing lots of text.</p>
<p>This next-word prediction has been around for years, and it partially solves our problem. If a model can predict that "meal" is likely after "I had a delicious," it must have learned something about what "delicious" means and what things can be delicious.</p>
<p>Word embeddings exploit this: <strong>words that appear in similar contexts have similar meanings.</strong></p>
<p>"Apple" and "orange" both show up near words like "fruit," "eat," "juice," "fresh." They appear in similar sentence structures: "I ate an <strong><em>," "The ___ was ripe," "A fresh </em></strong>___." So if you train a model to predict words from their surrounding context, words that fit the same contexts will develop similar internal representations. Process billions of sentences, and the model learns number patterns where semantically similar words end up close together.</p>
<hr />
<p>The training works like this: start with random real numbers for each word's vector. Read millions of sentences and try to predict words from context. When the model sees "I bought some ___ at the market," it should predict "apples" or "oranges" are likely, while "trucks" is not.</p>
<p>Each wrong prediction adjusts the vectors slightly. After processing billions of sentences, words that appear in similar contexts end up with similar number patterns. Instead of sparse vectors with mostly zeros, you get dense vectors - maybe 768 or 1536 dimensions - where every number carries some meaning.</p>
<pre class="mermaid"><code>block-beta
    columns 2
    A["One-hot (sparse)"]:1 B["Embedding (dense)"]:1
    C["apple → [1,0,0,0,0...]"]:1 D["apple → [0.23, -0.15, 0.89...]"]:1
    E["orange → [0,1,0,0,0...]"]:1 F["orange → [0.19, -0.14, 0.91...]"]:1</code></pre>
<p>The word "apple" might become <code>[0.23, -0.15, 0.89, ...]</code> while "orange" becomes <code>[0.19, -0.14, 0.91, ...]</code>. The numbers are similar because these words appeared in similar contexts. A word like "democracy" would have completely different numbers - it shows up near "vote," "government," "freedom."</p>
<p>We don't interpret individual dimensions - what does dimension 347 represent? We don't know and don't need to. What matters is that similar concepts end up pointing in similar directions in this high-dimensional space.</p>
<p>These vectors capture nuanced relationships. The famous example: <code>king - man + woman ≈ queen</code>. Vector arithmetic works because the model "learned" gender relationships from context.</p>
<h2 id="tokenization">Tokenization<a class="headerlink" href="#tokenization" title="Permanent link">&para;</a></h2>
<p>Before a model can work with your text, it needs to break it into pieces. Each piece gets an embedding, and those embeddings flow through the model. But how do we split text?</p>
<p>The obvious approach: split on spaces. "The cat sat" becomes ["The", "cat", "sat"]. Simple.</p>
<p>But this creates problems. English has hundreds of thousands of words. Add technical terms, names, typos, and other languages - the vocabulary would be enormous. Every word needs its own embedding vector. And what happens when you encounter a word you've never seen? "Cryptocurrency" probably wasn't in any training data from 2005.</p>
<p>What about the opposite extreme? Split into individual characters. The vocabulary shrinks to maybe 100 characters - letters, digits, punctuation. No out-of-vocabulary problem. Every possible word can be spelled.</p>
<p>But now "cat" becomes ["c", "a", "t"]. Three tokens instead of one. A sentence becomes dozens of tokens. The model has to learn that "c-a-t" means a furry animal - the relationship between characters and meaning isn't obvious. Sequences get very long, and longer sequences are slower and more expensive to process.</p>
<p>Subword tokenization finds a middle ground. Instead of words or characters, you learn a vocabulary of useful pieces. Common words like "the" stay whole. Rare words get split into recognizable chunks:</p>
<div class="language-text highlight"><pre><span></span><code><span id="__span-0-1"><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a>&quot;Hello, world!&quot; → [&quot;Hello&quot;, &quot;,&quot;, &quot; world&quot;, &quot;!&quot;]
</span><span id="__span-0-2"><a id="__codelineno-0-2" name="__codelineno-0-2" href="#__codelineno-0-2"></a>&quot;unhappiness&quot; → [&quot;un&quot;, &quot;happiness&quot;]
</span><span id="__span-0-3"><a id="__codelineno-0-3" name="__codelineno-0-3" href="#__codelineno-0-3"></a>&quot;cryptocurrency&quot; → [&quot;crypt&quot;, &quot;ocur&quot;, &quot;rency&quot;]
</span></code></pre></div>
<p>The model learns embeddings for these subwords. Linguists call these meaningful units "morphemes" - "un" often means negation, "ness" turns adjectives into nouns, "ed" marks past tense. Subword tokenization rediscovers this structure from data. The model can handle words it's never seen by combining pieces it knows.</p>
<p>This is important for you in two ways (beyond the fact that it's cool):</p>
<p><strong>Costs are per-token, not per-word.</strong> A short message with unusual words might cost more than a longer message with common words. "Supercalifragilisticexpialidocious" is 7 tokens, while "the cat sat on the mat" is 6.</p>
<p><strong>Context windows are measured in tokens.</strong> When a model has a "128K context window," that's tokens, not words. A document with lots of code, technical terms, or non-English text uses more tokens than you might expect.</p>
<p>You can experiment with this using OpenAI's tiktoken library or their online tokenizer to see exactly how your text gets split.</p>
<h2 id="how-language-models-work_1">How Language Models Work<a class="headerlink" href="#how-language-models-work_1" title="Permanent link">&para;</a></h2>
<p>We now have a way to turn text into meaningful numbers. But embeddings alone just give us word vectors - they don't generate text.</p>
<p>The next step was predicting not just similar words, but the actual next word in a sequence. This is the core insight behind modern LLMs: <strong>predict the next token.</strong></p>
<p>Given "The cat sat on the," what comes next? Probably "mat" or "floor" or "couch." Almost certainly not "democracy" or "quantum."</p>
<p>Training a language model means showing it billions of sentences and asking it to predict what comes next. When it guesses wrong, it adjusts its internal weights slightly. After seeing enough text, the model becomes very good at predicting likely continuations.</p>
<p>This sounds almost too simple. But predicting the next token requires a lot of implicit knowledge:</p>
<ul>
<li>Grammar: "The cat sat on the ___" needs a noun</li>
<li>Semantics: The noun should be something a cat can sit on</li>
<li>World knowledge: Cats sit on mats, floors, laps, keyboards</li>
<li>Context: If earlier text mentioned a garden, "bench" becomes more likely</li>
</ul>
<p>When you prompt a model with "Write a poem about the ocean," you're not giving it a special instruction. You're giving it tokens, and it's predicting what tokens would likely follow. Text that starts with "Write a poem" is usually followed by... a poem. So it generates one.</p>
<hr />
<p>Early language models processed text sequentially, one word at a time, carrying forward a compressed representation. They struggled with long-range dependencies. In "The book that the student borrowed was overdue," which word does "was" refer to? The book, not the student. Sequential models often got confused.</p>
<p>Attention mechanisms changed this. Instead of processing tokens in order, attention lets the model look at all tokens simultaneously and decide which ones are relevant to each other.</p>
<p>When processing "was" in our example, the model learns to pay attention to "book" (the subject) while mostly ignoring "student" (inside a relative clause). This attention pattern is learned from data, not programmed.</p>
<p>"Bank" in "river bank" attends strongly to "river." "Bank" in "bank account" attends to "account." Same word, different attention patterns, different meanings.</p>
<pre class="mermaid"><code>flowchart LR
    subgraph s1["river bank"]
        A[The] -.-&gt; B[river]
        B ==&gt; C[bank]
        D[is] -.-&gt; C
        E[muddy] -.-&gt; C
    end

    subgraph s2["bank account"]
        F[My] -.-&gt; I[bank]
        I ==&gt; G[account]
        H[is] -.-&gt; I
        J[empty] -.-&gt; I
    end</code></pre>
<p>The thick arrows show where "bank" pays the most attention - it looks at "river" in one context and "account" in the other to figure out its meaning.</p>
<hr />
<p>The Transformer architecture (2017's "Attention Is All You Need" paper) stacks many layers of attention. Each layer refines the representation, building increasingly abstract understanding of the text.</p>
<p>The key advantage is parallelization. Unlike sequential models that process one token at a time, transformers process all tokens simultaneously. This made it possible to train on vastly more data than before.</p>
<p>GPT models are transformers trained on internet-scale text. GPT-3 was trained on hundreds of billions of tokens. GPT-4 and Claude on even more. The architecture is conceptually simple: stack attention layers, train on lots of text, predict the next token.</p>
<p>What's interesting is that this simple objective leads to emergent capabilities. Models trained this way learn to answer questions (because Q&amp;A exists in training data), write code (because code exists), reason through problems (because step-by-step reasoning exists), and follow instructions (because instructional text exists).</p>
<p>Nobody explicitly programmed these capabilities. They emerged from scale and the training process.</p>
<h2 id="the-full-pipeline">The Full Pipeline<a class="headerlink" href="#the-full-pipeline" title="Permanent link">&para;</a></h2>
<p>When you call <code>agent.run("What's the weather in Paris?")</code>, this is the sequence:</p>
<pre class="mermaid"><code>flowchart TB
    A[Your text] --&gt; B[Tokenize]
    B --&gt; C[Embed tokens]
    C --&gt; D[Transformer layers]
    D --&gt; E[Probability distribution]
    E --&gt; F[Sample next token]
    F --&gt; G{Done?}
    G --&gt;|No| D
    G --&gt;|Yes| H[Response]</code></pre>
<p>Your text gets split into tokens, each token becomes an embedding vector, those vectors pass through transformer layers with attention refining the representation at each layer. The final layer produces a probability distribution over all possible next tokens, the model samples one (with randomness controlled by temperature), and then it repeats until a stop condition.</p>
<p>The response is built token by token, left to right. The model doesn't plan the whole response and then write it. It generates each token based on everything before it - your prompt plus whatever it has generated so far.</p>
<p>This explains why streaming works: each token can be sent as it's generated. It also explains why models sometimes contradict themselves or forget constraints - they're predicting locally, one token at a time, without a global plan.</p>
<h2 id="practical-implications">Practical Implications<a class="headerlink" href="#practical-implications" title="Permanent link">&para;</a></h2>
<p>Understanding this architecture changes how you think about building with LLMs:</p>
<p><strong>Prompts aren't instructions in a special language.</strong> You're providing context that makes certain continuations more likely. "You are a helpful assistant" works because text written by helpful assistants looks different from text written by unhelpful ones.</p>
<p><strong>Token limits are fundamental, not artificial.</strong> The model can only attend to tokens in its context window. If your conversation exceeds the limit, older messages get cut. This isn't a bug - it's how transformers work.</p>
<p><strong>Cost scales with tokens.</strong> Longer prompts, longer responses, more money. Every token matters when you're paying for millions of them.</p>
<p><strong>Temperature controls randomness.</strong> At temperature 0, the model always picks the most likely next token. Higher temperatures make less likely tokens more probable - more creative, or more chaotic.</p>
<p><strong>Models don't remember between calls.</strong> Each API call is independent. What seems like memory is you sending previous messages as part of the current prompt.</p>
<p>These aren't arbitrary API limitations, they're direct consequences of how language models work, their architecture.</p>
<hr />
<p>You now understand what happens between your code and the response. But knowing how models work doesn't tell you when to use them. In the next section, we'll look at what LLMs are actually good at - and more importantly, where they fail.</p>
<p><a class="md-button md-button--primary" href="../1-what-llms-can-and-cant-do/">What LLMs Can and Can't Do →</a></p>












                
              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
          <button type="button" class="md-top md-icon" data-md-component="top" hidden>
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8z"/></svg>
  Back to top
</button>
        
      </main>
      
        <footer class="md-footer">
  
    
      
      <nav class="md-footer__inner md-grid" aria-label="Footer" >
        
          
          <a href="../" class="md-footer__link md-footer__link--prev" aria-label="Previous: Learning Path">
            <div class="md-footer__button md-icon">
              
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
            </div>
            <div class="md-footer__title">
              <span class="md-footer__direction">
                Previous
              </span>
              <div class="md-ellipsis">
                Learning Path
              </div>
            </div>
          </a>
        
        
          
          <a href="../1-what-llms-can-and-cant-do/" class="md-footer__link md-footer__link--next" aria-label="Next: 1. What LLMs Can and Can&#39;t Do">
            <div class="md-footer__title">
              <span class="md-footer__direction">
                Next
              </span>
              <div class="md-ellipsis">
                1. What LLMs Can and Can't Do
              </div>
            </div>
            <div class="md-footer__button md-icon">
              
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11z"/></svg>
            </div>
          </a>
        
      </nav>
    
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
    <div class="md-copyright__highlight">
      &copy; 2025 <a href="https://benav.io" target="_blank">Benav Labs LLC</a>

    </div>
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
        
<div class="md-social">
  
    
    
    
    
    <a href="https://github.com/benavlabs/fastroai" target="_blank" rel="noopener" title="FastroAI on GitHub" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M173.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M252.8 8C114.1 8 8 113.3 8 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C436.2 457.8 504 362.9 504 252 504 113.3 391.5 8 252.8 8M105.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"/></svg>
    </a>
  
    
    
    
    
    <a href="https://discord.com/invite/TEmPs22gqB" target="_blank" rel="noopener" title="Discord Community" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 576 512"><!--! Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M492.5 69.8c-.2-.3-.4-.6-.8-.7-38.1-17.5-78.4-30-119.7-37.1-.4-.1-.8 0-1.1.1s-.6.4-.8.8c-5.5 9.9-10.5 20.2-14.9 30.6-44.6-6.8-89.9-6.8-134.4 0-4.5-10.5-9.5-20.7-15.1-30.6-.2-.3-.5-.6-.8-.8s-.7-.2-1.1-.2C162.5 39 122.2 51.5 84.1 69c-.3.1-.6.4-.8.7C7.1 183.5-13.8 294.6-3.6 404.2c0 .3.1.5.2.8s.3.4.5.6c44.4 32.9 94 58 146.8 74.2.4.1.8.1 1.1 0s.7-.4.9-.7c11.3-15.4 21.4-31.8 30-48.8.1-.2.2-.5.2-.8s0-.5-.1-.8-.2-.5-.4-.6-.4-.3-.7-.4c-15.8-6.1-31.2-13.4-45.9-21.9-.3-.2-.5-.4-.7-.6s-.3-.6-.3-.9 0-.6.2-.9.3-.5.6-.7c3.1-2.3 6.2-4.7 9.1-7.1.3-.2.6-.4.9-.4s.7 0 1 .1c96.2 43.9 200.4 43.9 295.5 0 .3-.1.7-.2 1-.2s.7.2.9.4c2.9 2.4 6 4.9 9.1 7.2.2.2.4.4.6.7s.2.6.2.9-.1.6-.3.9-.4.5-.6.6c-14.7 8.6-30 15.9-45.9 21.8-.2.1-.5.2-.7.4s-.3.4-.4.7-.1.5-.1.8.1.5.2.8c8.8 17 18.8 33.3 30 48.8.2.3.6.6.9.7s.8.1 1.1 0c52.9-16.2 102.6-41.3 147.1-74.2.2-.2.4-.4.5-.6s.2-.5.2-.8c12.3-126.8-20.5-236.9-86.9-334.5zm-302 267.7c-29 0-52.8-26.6-52.8-59.2s23.4-59.2 52.8-59.2c29.7 0 53.3 26.8 52.8 59.2 0 32.7-23.4 59.2-52.8 59.2m195.4 0c-29 0-52.8-26.6-52.8-59.2s23.4-59.2 52.8-59.2c29.7 0 53.3 26.8 52.8 59.2 0 32.7-23.2 59.2-52.8 59.2"/></svg>
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    
      
      <script id="__config" type="application/json">{"base": "../..", "features": ["navigation.instant", "navigation.instant.prefetch", "navigation.tabs", "navigation.indexes", "search.suggest", "content.code.annotate", "navigation.top", "navigation.footer"], "search": "../../assets/javascripts/workers/search.973d3a69.min.js", "tags": null, "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}, "version": null}</script>
    
    
      <script src="../../assets/javascripts/bundle.f55a23d4.min.js"></script>
      
    
  </body>
</html>